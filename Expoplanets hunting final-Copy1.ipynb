{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, roc_auc_score, accuracy_score, recall_score,precision_score\n",
    "from sklearn.preprocessing import StandardScaler, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On active l'utilisation du GPU pour accélérer l'entrainement des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On récupère les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./data/exoTest.csv')\n",
    "train_data = pd.read_csv('./data/exoTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aperçu des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On observe la répartition des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,8))\n",
    "colors = [\"0\", \"1\"]\n",
    "sns.countplot(x='LABEL', data=train_data, palette = \"Set2\")\n",
    "print(train_data['LABEL'].value_counts())\n",
    "plt.title('Stars Distribution \\n (0: Etoiles sans exoplanètes || 1: Etoiles avec exoplanètes)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les données sont nettoyées mais on vérifie qu'il n'y a pas de données manquantes au cas où"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre de valeurs nulles : \" + str(train_data.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage des corrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrMatrix = train_data.corr()\n",
    "# corrMatrix['LABEL'].sort_values(ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,15))\n",
    "# sns.heatmap(train_data.corr())\n",
    "# plt.title('Correlation in the data')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On sait que les étoiles ayant potentiellement des exoplanètes en orbites autour d'elles subissent une variation de leur \"flux\", de leur intensité lumineuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commençons avec les étoiles ne possédant pas d'exploplanetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data['LABEL'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On sélectionne 3 étoiles parmi les concernées (ici la ligne 37,2500 et 5086)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_1=[37,2500,5086]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "ax[0].hist(train_data.iloc[37,:], bins=200)\n",
    "ax[1].hist(train_data.iloc[2500,:], bins=200)\n",
    "ax[2].hist(train_data.iloc[5086,:], bins=200)\n",
    "\n",
    "ax[0].set_xlabel(\"Valeur des flux\")\n",
    "ax[1].set_xlabel(\"Valeur des flux\")\n",
    "ax[2].set_xlabel(\"Valeur des flux\")\n",
    "fig.suptitle(\"Répartition de la valeur des flux\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On remarque que l'intensité lumineuse de ces étoiles ne varie pas ou très peu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Au tour des étoiles dont on sait qu'elles possèdent des exoplanetes en orbite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data['LABEL'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On sélectionne 3 étoiles parmi les concernées (ici la ligne 0,26 et 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_1=[34,26,0]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "ax[0].hist(train_data.iloc[34,:], bins=200)\n",
    "ax[1].hist(train_data.iloc[26,:], bins=200)\n",
    "ax[2].hist(train_data.iloc[0,:], bins=200)\n",
    "\n",
    "ax[0].set_xlabel(\"Valeur des flux\")\n",
    "ax[1].set_xlabel(\"Valeur des flux\")\n",
    "ax[2].set_xlabel(\"Valeur des flux\")\n",
    "fig.suptitle(\"Répartition de la valeur des flux\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A l'inverses des étoiles n'ayant pas d'exoplanètes, on observe ici une importante variation de l'intensité lumineuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On convertit les valeurs du Label en binaire pour faciliter le traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_change = {1: 0,2: 1}\n",
    "train_data.LABEL = [label_change[item] for item in train_data.LABEL]\n",
    "test_data.LABEL = [label_change[item] for item in test_data.LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On a pu remarquer des anomalies dans les données (les flux), on peut donc essayer de visualiser cela avec des boites à moustache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5,figsize=(15, 6), sharey=True)\n",
    "fig.suptitle('Distribution of FLUX')\n",
    "\n",
    "sns.boxplot(ax=axes[0], data=train_data, x='LABEL', y='FLUX.1',palette=\"Set2\")\n",
    "sns.boxplot(ax=axes[1], data=train_data, x='LABEL', y='FLUX.2',palette=\"Set2\")\n",
    "sns.boxplot(ax=axes[2], data=train_data, x='LABEL', y='FLUX.3',palette=\"Set2\")\n",
    "sns.boxplot(ax=axes[3], data=train_data, x='LABEL', y='FLUX.4',palette=\"Set2\")\n",
    "sns.boxplot(ax=axes[4], data=train_data, x='LABEL', y='FLUX.5',palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On remarque donc des anomalies (des outliers), notamment pour les étoiles ne possédant pas d'exoplanetes, que l'on va retirer car ils peuvent perturber l'apprentissage du model plus tard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrait des anomalies (outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_outliers(df):\n",
    "#     for col in df.columns:\n",
    "#         print(\"capping the \",col)\n",
    "#         if (col != 'LABEL'):\n",
    "#             percentiles = df[col].quantile([0.02,0.98]).values\n",
    "#             df[col][df[col] <= percentiles[0]] = percentiles[0]\n",
    "#             df[col][df[col] >= percentiles[1]] = percentiles[1]\n",
    "#         else:\n",
    "#             df[col]=df[col]\n",
    "#     return df\n",
    "    \n",
    "\n",
    "# # final = remove_outliers(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### on retire les 2% des valeurs les plus hautes et les plus basses pour les remplacer par les valeurs les plus proches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5,figsize=(15, 6), sharey=True)\n",
    "fig.suptitle('Distribution of FLUX')\n",
    "\n",
    "sns.boxplot(ax=axes[0], data=train_data, x='LABEL', y='FLUX.1',palette=\"Set2\")\n",
    "sns.boxplot(ax=axes[1], data=train_data, x='LABEL', y='FLUX.2',palette=\"Set2\")\n",
    "sns.boxplot(ax=axes[2], data=train_data, x='LABEL', y='FLUX.3',palette=\"Set2\")\n",
    "sns.boxplot(ax=axes[3], data=train_data, x='LABEL', y='FLUX.4',palette=\"Set2\")\n",
    "sns.boxplot(ax=axes[4], data=train_data, x='LABEL', y='FLUX.5',palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On affiche la moyenne de variation lumineuse des étoiles possédant une ou des exoplanète(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data['LABEL'] == 1].std(axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On affiche la moyenne de variation lumineuse des étoiles ne possédant pas d'exoplanètes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data['LABEL'] == 0].std(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On observe que la variation lumineuse des étoiles possédant des exoplanètes est 2 fois plus importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On va split le dataset pour travailler dessus et pouvoir préparer le model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop([\"LABEL\"],axis=1)\n",
    "y_train = train_data[\"LABEL\"]   \n",
    "X_test = test_data.drop([\"LABEL\"],axis=1)\n",
    "y_test = test_data[\"LABEL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation de la donnée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On va normaliser les données pour la préparer pour le machine learning. L'idée est d'organiser toutes les données dans un même fourchette pour faciliter l'apprentissage (tout en gardant les ordres de grandeur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = normalize(X_train)\n",
    "# X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std_scaler = StandardScaler()\n",
    "# X_train = scaled = std_scaler.fit_transform(X_train)\n",
    "# X_test = std_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On définit les modèles qu'on va utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test d'algorithme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DT = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DT.fit(X_train, y_train)\n",
    "print(model_DT.__class__.__name__, model_DT.score(X_test, y_test))\n",
    "print(confusion_matrix(y_test, model_DT.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "plt.figure(figsize=(13,10))\n",
    "plt.subplot(221)\n",
    "sns.heatmap(confusion_matrix(y_test,model_DT.predict(X_test)),annot=True,cmap=\"viridis\",fmt = \"d\",linecolor=\"k\",linewidths=3)\n",
    "plt.title(\"CONFUSION MATRIX\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF.fit(X_train, y_train)\n",
    "print(model_RF.__class__.__name__, model_RF.score(X_test, y_test))\n",
    "print(confusion_matrix(y_test, model_RF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "plt.figure(figsize=(13,10))\n",
    "plt.subplot(221)\n",
    "sns.heatmap(confusion_matrix(y_test,model_RF.predict(X_test)),annot=True,cmap=\"viridis\",fmt = \"d\",linecolor=\"k\",linewidths=3)\n",
    "plt.title(\"CONFUSION MATRIX\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  On arrive pas ou très difficilement à déterminer si une étoile possède des planètes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nous sommes en présent d'un accuracy paradox dû au déséquilibre des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comme on l'a vu, l'échantillon est très déséquilibré. On va tenter de rééquilibrer les 2 catégories grâce à un SMOTE pour faciliter l'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=1)\n",
    "train_X, train_y = smote.fit_sample(train_data.drop('LABEL',axis=1), train_data['LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,8))\n",
    "colors = [\"0\", \"1\"]\n",
    "sns.countplot(x=train_y, palette = \"Set2\")\n",
    "plt.title('Stars Distribution \\n (0: Etoiles sans exoplanètes || 1: Etoiles avec exoplanètes)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On normalize et on scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = normalize(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "train_X = scaled = std_scaler.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On split les données smotée en train et validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(train_X, train_y, test_size=0.1, random_state=42)\n",
    "# , stratify=train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintenant qu'on a rééquilibré le data set on va pouvoir re-tester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DT_SMOTE = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DT_SMOTE.fit(train_X, train_y)\n",
    "print(model_DT_SMOTE.__class__.__name__, model_DT_SMOTE.score(test_X, test_y))\n",
    "print(confusion_matrix(test_y, model_DT_SMOTE.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "plt.figure(figsize=(13,10))\n",
    "plt.subplot(221)\n",
    "sns.heatmap(confusion_matrix(test_y,model_DT_SMOTE.predict(test_X)),annot=True,cmap=\"viridis\",fmt = \"d\",linecolor=\"k\",linewidths=3)\n",
    "plt.title(\"CONFUSION MATRIX\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_KNN_SMOTE = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_KNN_SMOTE.fit(train_X, train_y)\n",
    "print(model_KNN_SMOTE.__class__.__name__, model_KNN_SMOTE.score(test_X, test_y))\n",
    "print(confusion_matrix(test_y, model_KNN_SMOTE.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "plt.figure(figsize=(13,10))\n",
    "plt.subplot(221)\n",
    "sns.heatmap(confusion_matrix(test_y,model_KNN_SMOTE.predict(test_X)),annot=True,cmap=\"viridis\",fmt = \"d\",linecolor=\"k\",linewidths=3)\n",
    "plt.title(\"CONFUSION MATRIX\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF_SMOTE = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF_SMOTE = model_RF_SMOTE.fit(train_X, train_y)\n",
    "print(model_RF_SMOTE.__class__.__name__, model_RF_SMOTE.score(test_X, test_y))\n",
    "print(confusion_matrix(test_y, model_RF_SMOTE.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "plt.figure(figsize=(13,10))\n",
    "plt.subplot(221)\n",
    "sns.heatmap(confusion_matrix(test_y,model_RF_SMOTE.predict(test_X)),annot=True,cmap=\"viridis\",fmt = \"d\",linecolor=\"k\",linewidths=3)\n",
    "plt.title(\"CONFUSION MATRIX\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR_SMOTE = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR_SMOTE.fit(train_X, train_y)\n",
    "print(model_LR_SMOTE.__class__.__name__, model_LR_SMOTE.score(test_X, test_y))\n",
    "print(confusion_matrix(test_y, model_LR_SMOTE.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "plt.figure(figsize=(13,10))\n",
    "plt.subplot(221)\n",
    "sns.heatmap(confusion_matrix(test_y,model_LR_SMOTE.predict(test_X)),annot=True,cmap=\"viridis\",fmt = \"d\",linecolor=\"k\",linewidths=3)\n",
    "plt.title(\"CONFUSION MATRIX\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrait de l'ensemblevoting classifier car par interessant en terme de résultats\n",
    "\n",
    "for model in (model_DT_SMOTE, model_KNN_SMOTE,model_RF_SMOTE, model_LR_SMOTE):\n",
    "    model.fit(train_X, train_y)\n",
    "    \n",
    "    print(model.__class__.__name__)\n",
    "    print('Accuracy score:',accuracy_score(y_test, model.predict(X_test)))\n",
    "    print('ROCAUC score:',roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print('Precision score:',precision_score(y_test, model.predict(X_test)))\n",
    "    print('Recall score:',recall_score(y_test, model.predict(X_test)))\n",
    "    print('F1 score:',f1_score(y_test, model.predict(X_test)))\n",
    "    print(confusion_matrix(y_test, model.predict(X_test)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "\n",
    "    if 'SAP_FLUX' in df.columns:\n",
    "        df = transform_to_df(df)\n",
    "\n",
    "    df = df.dropna(axis=1)\n",
    "    \n",
    "    \n",
    "    if(df.size < 3197):\n",
    "        print(\"Pas assez de donnéees\")\n",
    "        return None\n",
    "    else:\n",
    "        print(\"Assez de donnéees, traitement en cours ....\")\n",
    "                  \n",
    "            \n",
    "        df = remove_outliers(df)\n",
    "        \n",
    "        df_normalized = normalize(df)\n",
    "        \n",
    "        std_scaler = StandardScaler()\n",
    "        df_normalized_scalled = scaled = std_scaler.fit_transform(df_normalized)\n",
    "        \n",
    "        df_transformed = pd.DataFrame(df_normalized_scalled) \n",
    "    \n",
    "        if df_transformed.size > 3197:\n",
    "            df_final = df_transformed[df_transformed.columns[0:3197]]\n",
    "    \n",
    "        print(\"Traitement terminé\")\n",
    "        return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isexoplanet(model, df):\n",
    "#     x = np.array(df[0]).reshape(1,3197)\n",
    "    x = np.array(df).reshape(1, -1)\n",
    "    \n",
    "    print(model.predict(x))\n",
    "    if model.predict(x) == 1:\n",
    "        print(\"Cette étoile possède des exoplanètes\")\n",
    "    elif model.predict(x) == 0:\n",
    "        print(\"Cette étoile ne possède pas d'exoplanètes\")\n",
    "        \n",
    "    print(model.predict_proba(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[372:373]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = test_data[372:373].copy()\n",
    "# show\n",
    "a = a.T\n",
    "a = a[1:-1]\n",
    "ax2 = a.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isexoplanet(model_DT, X_test[372:373])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_test[i] ==0 and y_pred[i].T == 1:\n",
    "        print(\"False Positive : \" + str(i))\n",
    "    if y_test[i] == 1 and y_pred[i].T == 0 :\n",
    "        print(\"False Negative  : \" + str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,10))\n",
    "plt.subplot(221)\n",
    "sns.heatmap(confusion_matrix(y_test,model_DT.predict(X_test)),annot=True,cmap=\"viridis\",fmt = \"d\",linecolor=\"k\",linewidths=3)\n",
    "plt.title(\"CONFUSION MATRIX\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ROCAUC score:',roc_auc_score(y_test, y_pred))\n",
    "print('Accuracy score:',accuracy_score(y_test, y_pred))\n",
    "print('Precision score:',precision_score(y_test, y_pred))\n",
    "print('Recall score:',recall_score(y_test, y_pred))\n",
    "print('F1 score:',f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
